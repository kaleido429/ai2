{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f512f95-9b6d-4358-92f1-94035fbf8ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe05525-f6a9-4396-9c7a-764efe39c5b2",
   "metadata": {},
   "source": [
    "# Utils\n",
    "### - Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a27cba-8cad-4ae9-b269-61398f2dc4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_actions(state, grid_reward):\n",
    "    actions = []\n",
    "    return actions\n",
    "\n",
    "def get_transition(state, action, grid_reward):\n",
    "    return next_state, reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a406ed-7920-44a4-9678-1c4373983299",
   "metadata": {},
   "source": [
    "# Utils\n",
    "### - Given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b87319-ccda-4cd0-9bc1-cd8a449c5e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_grid_world(obstacles):\n",
    "    grid_size = 7\n",
    "    grid_reward = np.full((grid_size, grid_size), -1)\n",
    "\n",
    "    for (x, y) in obstacles:\n",
    "        grid_reward[x, y] = -100\n",
    "\n",
    "    # Define start and end positions\n",
    "    start = (0, 0)\n",
    "    end = (6, 6)\n",
    "    grid_reward[end[0], end[1]] = 0\n",
    "\n",
    "    return grid_reward, start, end\n",
    "\n",
    "def print_policy(policy):\n",
    "    grid_size = policy.shape[0]\n",
    "    policy_symbols = np.full((grid_size, grid_size), ' ')\n",
    "    for x in range(grid_size):\n",
    "        for y in range(grid_size):\n",
    "            if (x, y) == (end[0], end[1]):\n",
    "                policy_symbols[x, y] = 'G'  # Goal\n",
    "            else:\n",
    "                policy_symbols[x, y] = ACTION_SYMBOLS.get(policy[x, y], ' ')\n",
    "    for row in policy_symbols:\n",
    "        print(' '.join(row))\n",
    "\n",
    "def visualize_map(data, title):\n",
    "    plt.imshow(data, cmap='gray', interpolation='nearest')\n",
    "    plt.colorbar(label='Value')\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            plt.text(j, i, f\"{data[i, j]:.1f}\", ha=\"center\", va=\"center\", color=\"Green\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel('X-axis')\n",
    "    plt.ylabel('Y-axis')\n",
    "    plt.show()\n",
    "\n",
    "def visualize_policy(policy, start, end, title, israndom):\n",
    "    grid_size = policy.shape[0]\n",
    "    policy_symbols = np.full((grid_size, grid_size), ' ', dtype=\"U10\")\n",
    "    for x in range(grid_size):\n",
    "        for y in range(grid_size):\n",
    "            if (x, y) == (end[0], end[1]):\n",
    "                policy_symbols[x, y] = 'G'  # Goal\n",
    "            elif (x, y) == (start[0], start[1]):\n",
    "                policy_symbols[x, y] = 'S'  # Start\n",
    "            else:\n",
    "                if israndom:\n",
    "                    policy_symbols[x, y] = ACTION_SYMBOLS.get(policy[x, y], ' ')\n",
    "                else:\n",
    "                    temp_policy_symbol = 0\n",
    "                    actions = [int(value) for value in str(policy[x, y])]\n",
    "                    for i, value in enumerate(actions):\n",
    "                        if i == 0:\n",
    "                            temp_policy_symbol = ACTION_SYMBOLS.get(value, ' ')\n",
    "                        else:\n",
    "                            temp_policy_symbol += ACTION_SYMBOLS.get(value, ' ')\n",
    "                    policy_symbols[x, y] = temp_policy_symbol\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    ax.set_xlim(0, grid_size)\n",
    "    ax.set_ylim(0, grid_size)\n",
    "    ax.set_xticks(np.arange(0, grid_size+1, 1))\n",
    "    ax.set_yticks(np.arange(0, grid_size+1, 1))\n",
    "    ax.set_yticklabels(np.arange(grid_size, -1, -1))\n",
    "    ax.grid(True)\n",
    "\n",
    "    for x in range(grid_size):\n",
    "        for y in range(grid_size):\n",
    "            if israndom:\n",
    "                ax.text(y + 0.5, grid_size - x - 0.5, policy_symbols[x, y],\n",
    "                        ha='center', va='center', fontsize=20)\n",
    "            else:\n",
    "                ax.text(y + 0.5, grid_size - x - 0.5, policy_symbols[x, y],\n",
    "                        ha='center', va='center', fontsize=10)\n",
    "            if grid[x, y] == -100:\n",
    "                rect = plt.Rectangle((y, grid_size - x - 1), 1, 1, facecolor='black')\n",
    "                ax.add_patch(rect)\n",
    "            elif (x, y) == (end[0], end[1]):\n",
    "                rect = plt.Rectangle((y, grid_size - x - 1), 1, 1, facecolor='green', alpha=0.3)\n",
    "                ax.add_patch(rect)\n",
    "            elif (x, y) == (start[0], start[1]):\n",
    "                rect = plt.Rectangle((y, grid_size - x - 1), 1, 1, facecolor='blue', alpha=0.3)\n",
    "                ax.add_patch(rect)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755be6b1-25ed-4802-9d4d-851fcb5392ac",
   "metadata": {},
   "source": [
    "# Policy initialization\n",
    "### - Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14280623-8cb4-4623-9335-897b7a45e8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_generator(grid_reward, israndom, isall=False):\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80252f8-a097-49a2-9fac-18ac55d2f758",
   "metadata": {},
   "source": [
    "# Policy evaluation\n",
    "### - Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b151e3-53aa-4e13-9376-263b88371d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_evaluation(grid_reward, policy, discount_factor=0.9, theta=1e-1, israndom=True):\n",
    "    return V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4445ff4e-f034-464f-b040-9c8281822a6d",
   "metadata": {},
   "source": [
    "# Policy improvement\n",
    "### - Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093ac467-7cbf-4e87-acb1-d82978d191e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_improvement(grid_reward, V, discount_factor=0.9):\n",
    "    return new_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e11d1d0-c889-4ec1-8650-5ccfb56d3f91",
   "metadata": {},
   "source": [
    "# Value iteration\n",
    "### - Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd6d5b7-76f2-4f69-be13-0879ca9b814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(grid_reward, discount_factor=0.9, theta=1e-1):\n",
    "    return V, policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caaba57-0924-4e36-863b-ad426c73dedb",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "### -Given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0662fed-f454-4e73-a843-a583421ea480",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTION_UP = 0\n",
    "ACTION_DOWN = 1\n",
    "ACTION_LEFT = 2\n",
    "ACTION_RIGHT = 3\n",
    "ACTIONS = [ACTION_UP, ACTION_DOWN, ACTION_LEFT, ACTION_RIGHT]\n",
    "ACTION_SYMBOLS = {ACTION_UP: '↑', ACTION_DOWN: '↓', ACTION_LEFT: '←', ACTION_RIGHT: '→'}\n",
    "\n",
    "border = f\"\\n{'='*60}\\n\"\n",
    "obstacles = [(0, 2), (1, 2), (3, 4), (3, 5), (6, 2), (6, 3)]\n",
    "grid, start, end = generate_grid_world(obstacles)\n",
    "print(border)\n",
    "visualize_map(grid, \"Grid initialization\")\n",
    "print(border)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3214e290-1399-47db-bf76-f8c046aec8b2",
   "metadata": {},
   "source": [
    "# Show results\n",
    "### - Random policy initialization\n",
    "### - Given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4b4ec1-4655-475d-94a7-cd13bf052747",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Policy initialization\n",
    "random_policy = policy_generator(grid, israndom=True)\n",
    "visualize_policy(random_policy, start, end, \"Random Policy initialization\", True)\n",
    "\n",
    "# Policy evaluation\n",
    "print(border)\n",
    "idx = 0\n",
    "for V_random in policy_evaluation(grid, random_policy, israndom=True):\n",
    "    idx += 1\n",
    "    visualize_map(V_random, f\"Value Function for policy evaluation for iter: {idx}\")\n",
    "    print(border)\n",
    "\n",
    "# Policy improvement\n",
    "improved_policy = policy_improvement(grid, V_random)\n",
    "visualize_policy(improved_policy, start, end, \"Improved Policy after Policy Improvement\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220af76c-0166-4896-9537-7ed188648b2d",
   "metadata": {},
   "source": [
    "# Show results\n",
    "### - All possible direction policy initialization\n",
    "### - Given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47add04-b0f0-4501-ba0d-d8994063ce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy initialization\n",
    "allpossibledirection_policy = policy_generator(grid, israndom=False)\n",
    "visualize_policy(allpossibledirection_policy, start, end, \"All possible direction Policy initialization\", False)\n",
    "\n",
    "# Policy evaluation\n",
    "print(border)\n",
    "idx = 0\n",
    "for V_random in policy_evaluation(grid, allpossibledirection_policy, discount_factor=0.9, israndom=False):\n",
    "    idx += 1\n",
    "    visualize_map(V_random, f\"Value Function for policy evaluation for iter: {idx}\")\n",
    "    print(border)\n",
    "\n",
    "# Policy improvement\n",
    "allpossibledirection_improved_policy = policy_improvement(grid, V_random)\n",
    "visualize_policy(allpossibledirection_improved_policy, start, end, \"Improved Policy after Policy Improvement\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc439d8-8384-43f1-9177-9068bd16f73a",
   "metadata": {},
   "source": [
    "# Show results\n",
    "### - Value iteration\n",
    "### - Given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e36b48-7f64-4361-af66-8014cb576eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_opt, optimal_policy = value_iteration(grid)\n",
    "visualize_map(V_opt, \"Optimal Value Function from Value Iteration\")\n",
    "\n",
    "visualize_policy(optimal_policy, start, end, \"Optimal Policy from Value Iteration\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ee8b82-1cea-438d-a9d8-4e87cc2e6f85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen",
   "language": "python",
   "name": "gen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
